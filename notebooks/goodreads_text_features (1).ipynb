{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "194201f6-026a-4296-9403-61589e92bd48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\n",
    "    \n",
    ")\n",
    "\n",
    "base = \"abfss://lakehouse@goodreadsreviews60105179.dfs.core.windows.net/gold\"\n",
    "input_path  = f\"{base}/features_v1\"     # input from Lab 3\n",
    "output_base = f\"{base}/features_v2\"     # output for Lab 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd955840-7465-4250-8825-5796fb647735",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>book_id</th><th>review_id</th><th>title</th><th>author_id</th><th>author_name</th><th>user_id</th><th>rating</th><th>review_text</th><th>language_code</th><th>n_votes</th><th>date_added</th><th>review_length</th><th>review_length_in_words</th><th>average_rating</th><th>number_of_reviews</th></tr></thead><tbody><tr><td>7663760</td><td>fa241e939d2218940d17cff6fc30bca4</td><td>fooling some of the people all of the time: a long short (and now complete) story</td><td>1397426</td><td>david einhorn</td><td>0c5b36407771dfd65acdd812ecd51705</td><td>4.0</td><td>investing is an obsession and not a job.i think few exemplify that more than david einhorn, one of the smartest fundamental investors in the current era. \n",
       " in a world, where short-sellers are castigated as profiteers and trouble makers, mr einhorn demonstrates through his most public short that fundamental short-selling is the only tool to expose fraud and corruption in financial markets.his appeal to regulators to close loopholes that allow companies to feed off tax-payer dollars is genuine but it's difficult to be an optimist when incentives are so perverse despite all the outrage in the aftermath of the financial crisis.all i can say is that mr einhorn and his ilk, continue to be the de-facto regulators of a broken financial system and if they profit from that, well isn't it just right when you see the breadth of the work they put into doing so.</td><td>eng</td><td>2071</td><td>2015-04-07</td><td>860</td><td>145</td><td>3.125</td><td>8</td></tr><tr><td>22387890</td><td>2628b9004c4b6710aa0c20ce094da2c1</td><td>deep water</td><td>5341919</td><td>coral moore</td><td>b78a9143ca2f0c4c7361694dc6cb0500</td><td>3.0</td><td>i liked this story despite not being entirely sold on the attraction between mario and jordan which result pretty much in insta-love. but it was still a nice short and sweet story.</td><td>eng</td><td>30</td><td>2014-06-02</td><td>180</td><td>32</td><td>3.5</td><td>2</td></tr><tr><td>1096390</td><td>ec6f00823d47459dc2c70fea9559c605</td><td>the uncommon reader</td><td>11781</td><td>alan bennett</td><td>c3fa377cfc84401747630b98f92758c9</td><td>4.0</td><td>cute story with lots of british humor on the perils of reading too much. like that could ever happen!</td><td>eng</td><td>17355</td><td>2010-01-05</td><td>101</td><td>19</td><td>3.9038031319910513</td><td>447</td></tr><tr><td>13166894</td><td>e995dd91ce98a48306e5be8d15f97c8d</td><td>death at seaworld: shamu and the dark side of killer whales in captivity</td><td>6435477</td><td>david  kirby</td><td>ddc44923909c38b4d149a38431105943</td><td>4.0</td><td>this was a good book with a very important message that everybody should at least be aware of. while i agree with a lot of the position this book took,i do have a few notes: \n",
       " - it clearly had an agenda, which is okay, but even though i share the same position on whales in captivity, it is quite biased and only gives a small glimpse into the other side of the debate. \n",
       " - it get's extremely repetitive. there were points where i had to check to make sure i hadn't lost my place because it felt like i had just read the exact same thing in previous chapters. \n",
       " - personally, while i was completely interested (especially being that orcas are my favourite animal), there were points, particularly when discussing the legal battle issues where i started to glaze over a little bit and speed read to get through it. \n",
       " all in all though, this was a very thought-provoking read that i overall very much enjoyed.</td><td>eng</td><td>15</td><td>2013-07-10</td><td>907</td><td>166</td><td>4.0</td><td>1</td></tr><tr><td>25430624</td><td>d6120da6fdef79aaa9e11c623e4b9559</td><td>abc dream</td><td>8108153</td><td>kim krans</td><td>419dfd723edeb5e27f50aa2382f9aa86</td><td>5.0</td><td>concept: 5 stars \n",
       " art: 5 stars \n",
       " alphabet book with marvelous illustrations that include various items for each letter. in each illustration, readers discern all the words they can that begin with the featured letter, then check their answers against the list in the back of the book. fun, interactive way to learn the alphabet.</td><td></td><td>122</td><td>2017-01-02</td><td>329</td><td>54</td><td>4.545454545454546</td><td>11</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "7663760",
         "fa241e939d2218940d17cff6fc30bca4",
         "fooling some of the people all of the time: a long short (and now complete) story",
         "1397426",
         "david einhorn",
         "0c5b36407771dfd65acdd812ecd51705",
         4,
         "investing is an obsession and not a job.i think few exemplify that more than david einhorn, one of the smartest fundamental investors in the current era. \n in a world, where short-sellers are castigated as profiteers and trouble makers, mr einhorn demonstrates through his most public short that fundamental short-selling is the only tool to expose fraud and corruption in financial markets.his appeal to regulators to close loopholes that allow companies to feed off tax-payer dollars is genuine but it's difficult to be an optimist when incentives are so perverse despite all the outrage in the aftermath of the financial crisis.all i can say is that mr einhorn and his ilk, continue to be the de-facto regulators of a broken financial system and if they profit from that, well isn't it just right when you see the breadth of the work they put into doing so.",
         "eng",
         2071,
         "2015-04-07",
         860,
         145,
         3.125,
         8
        ],
        [
         "22387890",
         "2628b9004c4b6710aa0c20ce094da2c1",
         "deep water",
         "5341919",
         "coral moore",
         "b78a9143ca2f0c4c7361694dc6cb0500",
         3,
         "i liked this story despite not being entirely sold on the attraction between mario and jordan which result pretty much in insta-love. but it was still a nice short and sweet story.",
         "eng",
         30,
         "2014-06-02",
         180,
         32,
         3.5,
         2
        ],
        [
         "1096390",
         "ec6f00823d47459dc2c70fea9559c605",
         "the uncommon reader",
         "11781",
         "alan bennett",
         "c3fa377cfc84401747630b98f92758c9",
         4,
         "cute story with lots of british humor on the perils of reading too much. like that could ever happen!",
         "eng",
         17355,
         "2010-01-05",
         101,
         19,
         3.9038031319910513,
         447
        ],
        [
         "13166894",
         "e995dd91ce98a48306e5be8d15f97c8d",
         "death at seaworld: shamu and the dark side of killer whales in captivity",
         "6435477",
         "david  kirby",
         "ddc44923909c38b4d149a38431105943",
         4,
         "this was a good book with a very important message that everybody should at least be aware of. while i agree with a lot of the position this book took,i do have a few notes: \n - it clearly had an agenda, which is okay, but even though i share the same position on whales in captivity, it is quite biased and only gives a small glimpse into the other side of the debate. \n - it get's extremely repetitive. there were points where i had to check to make sure i hadn't lost my place because it felt like i had just read the exact same thing in previous chapters. \n - personally, while i was completely interested (especially being that orcas are my favourite animal), there were points, particularly when discussing the legal battle issues where i started to glaze over a little bit and speed read to get through it. \n all in all though, this was a very thought-provoking read that i overall very much enjoyed.",
         "eng",
         15,
         "2013-07-10",
         907,
         166,
         4,
         1
        ],
        [
         "25430624",
         "d6120da6fdef79aaa9e11c623e4b9559",
         "abc dream",
         "8108153",
         "kim krans",
         "419dfd723edeb5e27f50aa2382f9aa86",
         5,
         "concept: 5 stars \n art: 5 stars \n alphabet book with marvelous illustrations that include various items for each letter. in each illustration, readers discern all the words they can that begin with the featured letter, then check their answers against the list in the back of the book. fun, interactive way to learn the alphabet.",
         "",
         122,
         "2017-01-02",
         329,
         54,
         4.545454545454546,
         11
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "book_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "review_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "title",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "author_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "author_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "user_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "rating",
         "type": "\"float\""
        },
        {
         "metadata": "{}",
         "name": "review_text",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "language_code",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "n_votes",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "date_added",
         "type": "\"date\""
        },
        {
         "metadata": "{}",
         "name": "review_length",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "review_length_in_words",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "average_rating",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "number_of_reviews",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- book_id: string (nullable = true)\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- author_id: string (nullable = true)\n",
      " |-- author_name: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- rating: float (nullable = true)\n",
      " |-- review_text: string (nullable = true)\n",
      " |-- language_code: string (nullable = true)\n",
      " |-- n_votes: integer (nullable = true)\n",
      " |-- date_added: date (nullable = true)\n",
      " |-- review_length: integer (nullable = true)\n",
      " |-- review_length_in_words: integer (nullable = true)\n",
      " |-- average_rating: double (nullable = true)\n",
      " |-- number_of_reviews: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load cleaned Gold dataset from Lab 3 (features_v1)\n",
    "df = spark.read.format(\"delta\").load(input_path)\n",
    "\n",
    "# Quick preview to confirm it's loaded\n",
    "display(df.limit(5))\n",
    "df.printSchema()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fa29b6b-9cb3-49d2-8b00-f6e7ded8e21e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Splitting the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bbb2f47-b27a-4b68-bd44-bf419976f19b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 6759016\n",
      "Validation rows: 1446141\n",
      "Test rows: 1447906\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train (70%), validation (15%), and test (15%)\n",
    "train_df, val_df, test_df = df.randomSplit([0.7, 0.15, 0.15], seed=60105179)\n",
    "\n",
    "# Save these splits in the Gold layer under features_v2\n",
    "train_df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").save(f\"{output_base}/train_raw\")\n",
    "val_df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").save(f\"{output_base}/val_raw\")\n",
    "test_df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").save(f\"{output_base}/test_raw\")\n",
    "\n",
    "# Print record counts to confirm\n",
    "print(f\"Train rows: {train_df.count()}\")\n",
    "print(f\"Validation rows: {val_df.count()}\")\n",
    "print(f\"Test rows: {test_df.count()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2688902c-62ef-449c-b80f-b4e7646d7d9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Text Cleaning and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ee53aea-cf8a-49ec-8797-54dee10f4c5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emoji\n",
      "  Downloading emoji-2.15.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Downloading emoji-2.15.0-py3-none-any.whl (608 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/608.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m608.4/608.4 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: emoji\n",
      "Successfully installed emoji-2.15.0\n",
      "\u001b[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install emoji\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82650af6-dd1c-4029-ac01-1b0081f46c1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>review_text</th></tr></thead><tbody><tr><td>spoiler alert girl meets lion lion meets burglar burglar meets nasty end girl cleans up evidence the end</td></tr><tr><td>a little gruesome the robber gets munch out of existence if it doesnt got over your head but my son loved this book the drawings are fun and the rhyming story is cute</td></tr><tr><td>an important word to the church you can be an obstacle or you can be a nurturer of gifts and callings of young people called to ministry my full review is found here URL</td></tr><tr><td>jocelyn dreams of max almost every night but last night was different its christmas morning and last nights dreams weigh heavy on her mind as she waits for her visiting old college room mate to wake to talk to her first a ghost here crazy grandmothers ghost warning and wanting to help her then three visitors after that and not all were welcomed guests past present and future men collide in one night oh this novella is a very interesting and sexy vampire twist on a christmas carol oh the hints in this novella there is something special about jocelyn what im curious max is remembered and im curious how he manages to do this the current boyfriend that cute guy named chad from the dance in of course i tryyeah its him yum jocelyn has been trying to be stronger since max shes started selfdefense classes and fighting better along with becoming more physically fit than she ever has i have to say i love the description of the ghost yes its someone she knew shes the antithesis of the fairy godmother id always wished for all she needs now is a lit cigar between her fingers to totally bastardize that particular childhood fantasy the telling of this story starts with jocelyn waiting for kait then when she comes out we get the front row seat of the happenings as we are there with her then we are back to the morning and kait leaves and jocelyn gets ready for christmas at her mothers and waits for her boyfriend we seen clues that last night might not have been a dream but then things change and answers arent connecting with what happened so maybe it all was after being out with the girls drinking and all im left curious as to what was real and what was a dream i think its all real but there is more than real and not here theres secrets i want to know what they are there is something special about jocelyn but im not sure what exactly it is ill definitely be reading the first novel kiss of death very soon to figure it all out this is definitely a romance with intimate moments</td></tr><tr><td>NUM out of NUM stars why and how to forgive and reap the benefits october NUM NUM by becca chopra author of the chakra diaries big island of hawaii see all my reviews vine voice this review is from forgive to win end selfsabotage get everything you want paperback buddha said holding on to anger is like grasping a hot coal with the intent of throwing it at someone else you are the one who gets burned counseling a client with this wise saying she retorted forgiveness is not a concept in my religion well we are all holding on to anger of one sort or another against one parent or another an exlover exhusband exemployer etc and forgive to win finally explains fully and completely why its necessary and in our own best interests to let it go whatever your beliefs there are many wonderful books on forgiveness already on my bookshelf but i welcomed this one because it lays out a structured daily program its not just a philosophical treatise the steps suggested help train ourselves to let go of selfsabotaging behavior and learn to love ourselves by loving and forgiving others no matter what theyve done once our selfesteem is raised to the heights possible through selflove theres nothing you cant achieve forgiveness may seem like an easy task but its not and dr jacobson guides the reader in how to forgive his forgiveness diet is a unique set of recommendations to help us establish and maintain the NUM day commitment to acts of kindness and forgiveness that could literally change ones life he also includes forgiveness affirmations and visualizations that i have already used to great benefit looking at it from the vantage point of health anger throws us offbalance and creates tension that can lead to chronic pain and disease forgiveness opens the floodgates of our bodys own healing energy and keeps us grounded alert empowered and able to recognize opportunities for success the last chapter of the book is entitled getting everything you want if you dont already have it its time to get this book namaste becca chopra author of the chakra diaries URL</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "spoiler alert girl meets lion lion meets burglar burglar meets nasty end girl cleans up evidence the end"
        ],
        [
         "a little gruesome the robber gets munch out of existence if it doesnt got over your head but my son loved this book the drawings are fun and the rhyming story is cute"
        ],
        [
         "an important word to the church you can be an obstacle or you can be a nurturer of gifts and callings of young people called to ministry my full review is found here URL"
        ],
        [
         "jocelyn dreams of max almost every night but last night was different its christmas morning and last nights dreams weigh heavy on her mind as she waits for her visiting old college room mate to wake to talk to her first a ghost here crazy grandmothers ghost warning and wanting to help her then three visitors after that and not all were welcomed guests past present and future men collide in one night oh this novella is a very interesting and sexy vampire twist on a christmas carol oh the hints in this novella there is something special about jocelyn what im curious max is remembered and im curious how he manages to do this the current boyfriend that cute guy named chad from the dance in of course i tryyeah its him yum jocelyn has been trying to be stronger since max shes started selfdefense classes and fighting better along with becoming more physically fit than she ever has i have to say i love the description of the ghost yes its someone she knew shes the antithesis of the fairy godmother id always wished for all she needs now is a lit cigar between her fingers to totally bastardize that particular childhood fantasy the telling of this story starts with jocelyn waiting for kait then when she comes out we get the front row seat of the happenings as we are there with her then we are back to the morning and kait leaves and jocelyn gets ready for christmas at her mothers and waits for her boyfriend we seen clues that last night might not have been a dream but then things change and answers arent connecting with what happened so maybe it all was after being out with the girls drinking and all im left curious as to what was real and what was a dream i think its all real but there is more than real and not here theres secrets i want to know what they are there is something special about jocelyn but im not sure what exactly it is ill definitely be reading the first novel kiss of death very soon to figure it all out this is definitely a romance with intimate moments"
        ],
        [
         "NUM out of NUM stars why and how to forgive and reap the benefits october NUM NUM by becca chopra author of the chakra diaries big island of hawaii see all my reviews vine voice this review is from forgive to win end selfsabotage get everything you want paperback buddha said holding on to anger is like grasping a hot coal with the intent of throwing it at someone else you are the one who gets burned counseling a client with this wise saying she retorted forgiveness is not a concept in my religion well we are all holding on to anger of one sort or another against one parent or another an exlover exhusband exemployer etc and forgive to win finally explains fully and completely why its necessary and in our own best interests to let it go whatever your beliefs there are many wonderful books on forgiveness already on my bookshelf but i welcomed this one because it lays out a structured daily program its not just a philosophical treatise the steps suggested help train ourselves to let go of selfsabotaging behavior and learn to love ourselves by loving and forgiving others no matter what theyve done once our selfesteem is raised to the heights possible through selflove theres nothing you cant achieve forgiveness may seem like an easy task but its not and dr jacobson guides the reader in how to forgive his forgiveness diet is a unique set of recommendations to help us establish and maintain the NUM day commitment to acts of kindness and forgiveness that could literally change ones life he also includes forgiveness affirmations and visualizations that i have already used to great benefit looking at it from the vantage point of health anger throws us offbalance and creates tension that can lead to chronic pain and disease forgiveness opens the floodgates of our bodys own healing energy and keeps us grounded alert empowered and able to recognize opportunities for success the last chapter of the book is entitled getting everything you want if you dont already have it its time to get this book namaste becca chopra author of the chakra diaries URL"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "review_text",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Import required libraries ---\n",
    "import re, string, emoji\n",
    "from pyspark.sql.functions import udf, col, length\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# --- Step 1: Define the text cleaning function ---\n",
    "def clean_text(t):\n",
    "    if t is None:\n",
    "        return \"\"\n",
    "    t = t.lower()  # convert to lowercase\n",
    "    t = re.sub(r'(https?://\\S+|www\\.\\S+)', ' <URL> ', t)  # replace URLs\n",
    "    t = emoji.replace_emoji(t, replace=' <EMOJI> ')        # replace emojis\n",
    "    t = re.sub(r'\\b\\d+(\\.\\d+)?\\b', ' <NUM> ', t)           # replace numbers\n",
    "    t = t.translate(str.maketrans('', '', string.punctuation))  # remove punctuation\n",
    "    t = re.sub(r'\\s+', ' ', t).strip()                     # remove extra spaces\n",
    "    return t\n",
    "\n",
    "# --- Step 2: Register the UDF ---\n",
    "clean_udf = udf(clean_text, StringType())\n",
    "\n",
    "# --- Step 3: Apply cleaning directly to 'review_text' column ---\n",
    "train_df = train_df.withColumn(\"review_text\", clean_udf(col(\"review_text\")))\n",
    "\n",
    "# --- Step 4: Filter out empty or very short reviews (<10 characters) ---\n",
    "train_df = train_df.filter(length(col(\"review_text\")) >= 10)\n",
    "\n",
    "# --- Step 5: Preview cleaned text ---\n",
    "display(train_df.select(\"review_text\").limit(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "000c4b19-7a4c-4041-9cd2-18837de78a88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Extract text-based features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab7f2b3c-a8a9-40a9-ac18-2b15be80ee47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Basic Text Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbc3a5fc-8456-43dd-afb7-c798e168814c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>review_text</th><th>review_length_words</th><th>review_length_chars</th></tr></thead><tbody><tr><td>spoiler alert girl meets lion lion meets burglar burglar meets nasty end girl cleans up evidence the end</td><td>18</td><td>104</td></tr><tr><td>a little gruesome the robber gets munch out of existence if it doesnt got over your head but my son loved this book the drawings are fun and the rhyming story is cute</td><td>33</td><td>166</td></tr><tr><td>an important word to the church you can be an obstacle or you can be a nurturer of gifts and callings of young people called to ministry my full review is found here URL</td><td>34</td><td>169</td></tr><tr><td>jocelyn dreams of max almost every night but last night was different its christmas morning and last nights dreams weigh heavy on her mind as she waits for her visiting old college room mate to wake to talk to her first a ghost here crazy grandmothers ghost warning and wanting to help her then three visitors after that and not all were welcomed guests past present and future men collide in one night oh this novella is a very interesting and sexy vampire twist on a christmas carol oh the hints in this novella there is something special about jocelyn what im curious max is remembered and im curious how he manages to do this the current boyfriend that cute guy named chad from the dance in of course i tryyeah its him yum jocelyn has been trying to be stronger since max shes started selfdefense classes and fighting better along with becoming more physically fit than she ever has i have to say i love the description of the ghost yes its someone she knew shes the antithesis of the fairy godmother id always wished for all she needs now is a lit cigar between her fingers to totally bastardize that particular childhood fantasy the telling of this story starts with jocelyn waiting for kait then when she comes out we get the front row seat of the happenings as we are there with her then we are back to the morning and kait leaves and jocelyn gets ready for christmas at her mothers and waits for her boyfriend we seen clues that last night might not have been a dream but then things change and answers arent connecting with what happened so maybe it all was after being out with the girls drinking and all im left curious as to what was real and what was a dream i think its all real but there is more than real and not here theres secrets i want to know what they are there is something special about jocelyn but im not sure what exactly it is ill definitely be reading the first novel kiss of death very soon to figure it all out this is definitely a romance with intimate moments</td><td>372</td><td>1992</td></tr><tr><td>NUM out of NUM stars why and how to forgive and reap the benefits october NUM NUM by becca chopra author of the chakra diaries big island of hawaii see all my reviews vine voice this review is from forgive to win end selfsabotage get everything you want paperback buddha said holding on to anger is like grasping a hot coal with the intent of throwing it at someone else you are the one who gets burned counseling a client with this wise saying she retorted forgiveness is not a concept in my religion well we are all holding on to anger of one sort or another against one parent or another an exlover exhusband exemployer etc and forgive to win finally explains fully and completely why its necessary and in our own best interests to let it go whatever your beliefs there are many wonderful books on forgiveness already on my bookshelf but i welcomed this one because it lays out a structured daily program its not just a philosophical treatise the steps suggested help train ourselves to let go of selfsabotaging behavior and learn to love ourselves by loving and forgiving others no matter what theyve done once our selfesteem is raised to the heights possible through selflove theres nothing you cant achieve forgiveness may seem like an easy task but its not and dr jacobson guides the reader in how to forgive his forgiveness diet is a unique set of recommendations to help us establish and maintain the NUM day commitment to acts of kindness and forgiveness that could literally change ones life he also includes forgiveness affirmations and visualizations that i have already used to great benefit looking at it from the vantage point of health anger throws us offbalance and creates tension that can lead to chronic pain and disease forgiveness opens the floodgates of our bodys own healing energy and keeps us grounded alert empowered and able to recognize opportunities for success the last chapter of the book is entitled getting everything you want if you dont already have it its time to get this book namaste becca chopra author of the chakra diaries URL</td><td>361</td><td>2069</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "spoiler alert girl meets lion lion meets burglar burglar meets nasty end girl cleans up evidence the end",
         18,
         104
        ],
        [
         "a little gruesome the robber gets munch out of existence if it doesnt got over your head but my son loved this book the drawings are fun and the rhyming story is cute",
         33,
         166
        ],
        [
         "an important word to the church you can be an obstacle or you can be a nurturer of gifts and callings of young people called to ministry my full review is found here URL",
         34,
         169
        ],
        [
         "jocelyn dreams of max almost every night but last night was different its christmas morning and last nights dreams weigh heavy on her mind as she waits for her visiting old college room mate to wake to talk to her first a ghost here crazy grandmothers ghost warning and wanting to help her then three visitors after that and not all were welcomed guests past present and future men collide in one night oh this novella is a very interesting and sexy vampire twist on a christmas carol oh the hints in this novella there is something special about jocelyn what im curious max is remembered and im curious how he manages to do this the current boyfriend that cute guy named chad from the dance in of course i tryyeah its him yum jocelyn has been trying to be stronger since max shes started selfdefense classes and fighting better along with becoming more physically fit than she ever has i have to say i love the description of the ghost yes its someone she knew shes the antithesis of the fairy godmother id always wished for all she needs now is a lit cigar between her fingers to totally bastardize that particular childhood fantasy the telling of this story starts with jocelyn waiting for kait then when she comes out we get the front row seat of the happenings as we are there with her then we are back to the morning and kait leaves and jocelyn gets ready for christmas at her mothers and waits for her boyfriend we seen clues that last night might not have been a dream but then things change and answers arent connecting with what happened so maybe it all was after being out with the girls drinking and all im left curious as to what was real and what was a dream i think its all real but there is more than real and not here theres secrets i want to know what they are there is something special about jocelyn but im not sure what exactly it is ill definitely be reading the first novel kiss of death very soon to figure it all out this is definitely a romance with intimate moments",
         372,
         1992
        ],
        [
         "NUM out of NUM stars why and how to forgive and reap the benefits october NUM NUM by becca chopra author of the chakra diaries big island of hawaii see all my reviews vine voice this review is from forgive to win end selfsabotage get everything you want paperback buddha said holding on to anger is like grasping a hot coal with the intent of throwing it at someone else you are the one who gets burned counseling a client with this wise saying she retorted forgiveness is not a concept in my religion well we are all holding on to anger of one sort or another against one parent or another an exlover exhusband exemployer etc and forgive to win finally explains fully and completely why its necessary and in our own best interests to let it go whatever your beliefs there are many wonderful books on forgiveness already on my bookshelf but i welcomed this one because it lays out a structured daily program its not just a philosophical treatise the steps suggested help train ourselves to let go of selfsabotaging behavior and learn to love ourselves by loving and forgiving others no matter what theyve done once our selfesteem is raised to the heights possible through selflove theres nothing you cant achieve forgiveness may seem like an easy task but its not and dr jacobson guides the reader in how to forgive his forgiveness diet is a unique set of recommendations to help us establish and maintain the NUM day commitment to acts of kindness and forgiveness that could literally change ones life he also includes forgiveness affirmations and visualizations that i have already used to great benefit looking at it from the vantage point of health anger throws us offbalance and creates tension that can lead to chronic pain and disease forgiveness opens the floodgates of our bodys own healing energy and keeps us grounded alert empowered and able to recognize opportunities for success the last chapter of the book is entitled getting everything you want if you dont already have it its time to get this book namaste becca chopra author of the chakra diaries URL",
         361,
         2069
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "review_text",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "review_length_words",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "review_length_chars",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Basic Text Features ---\n",
    "\n",
    "from pyspark.sql.functions import size, split, length\n",
    "\n",
    "# Add columns for number of words and characters\n",
    "train_df = train_df.withColumn(\"review_length_words\", size(split(col(\"review_text\"), \" \")))\n",
    "train_df = train_df.withColumn(\"review_length_chars\", length(col(\"review_text\")))\n",
    "\n",
    "# Preview results\n",
    "display(train_df.select(\"review_text\", \"review_length_words\", \"review_length_chars\").limit(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65aae7a6-f733-446a-ad87-ffc7c0a4c896",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Sentiment Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be1ad2ae-7dde-4b24-affe-955e1c2b1004",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: click in /databricks/python3/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /databricks/python3/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/40.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tqdm (from nltk)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/57.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (803 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/803.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.5/803.5 kB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/78.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm, regex, nltk\n",
      "Successfully installed nltk-3.9.2 regex-2025.11.3 tqdm-4.67.1\n",
      "\u001b[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb2e5d3b-291d-4694-8319-fe1d3329189f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/spark-6a3e73ef-c784-4316-b3b1-4b/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>review_text</th><th>sentiment_pos</th><th>sentiment_neg</th><th>sentiment_neu</th><th>sentiment_compound</th></tr></thead><tbody><tr><td>spoiler alert girl meets lion lion meets burglar burglar meets nasty end girl cleans up evidence the end</td><td>0.101</td><td>0.165</td><td>0.734</td><td>-0.34</td></tr><tr><td>a little gruesome the robber gets munch out of existence if it doesnt got over your head but my son loved this book the drawings are fun and the rhyming story is cute</td><td>0.314</td><td>0.049</td><td>0.637</td><td>0.9278</td></tr><tr><td>an important word to the church you can be an obstacle or you can be a nurturer of gifts and callings of young people called to ministry my full review is found here URL</td><td>0.126</td><td>0.067</td><td>0.806</td><td>0.296</td></tr><tr><td>jocelyn dreams of max almost every night but last night was different its christmas morning and last nights dreams weigh heavy on her mind as she waits for her visiting old college room mate to wake to talk to her first a ghost here crazy grandmothers ghost warning and wanting to help her then three visitors after that and not all were welcomed guests past present and future men collide in one night oh this novella is a very interesting and sexy vampire twist on a christmas carol oh the hints in this novella there is something special about jocelyn what im curious max is remembered and im curious how he manages to do this the current boyfriend that cute guy named chad from the dance in of course i tryyeah its him yum jocelyn has been trying to be stronger since max shes started selfdefense classes and fighting better along with becoming more physically fit than she ever has i have to say i love the description of the ghost yes its someone she knew shes the antithesis of the fairy godmother id always wished for all she needs now is a lit cigar between her fingers to totally bastardize that particular childhood fantasy the telling of this story starts with jocelyn waiting for kait then when she comes out we get the front row seat of the happenings as we are there with her then we are back to the morning and kait leaves and jocelyn gets ready for christmas at her mothers and waits for her boyfriend we seen clues that last night might not have been a dream but then things change and answers arent connecting with what happened so maybe it all was after being out with the girls drinking and all im left curious as to what was real and what was a dream i think its all real but there is more than real and not here theres secrets i want to know what they are there is something special about jocelyn but im not sure what exactly it is ill definitely be reading the first novel kiss of death very soon to figure it all out this is definitely a romance with intimate moments</td><td>0.174</td><td>0.104</td><td>0.722</td><td>0.9877</td></tr><tr><td>NUM out of NUM stars why and how to forgive and reap the benefits october NUM NUM by becca chopra author of the chakra diaries big island of hawaii see all my reviews vine voice this review is from forgive to win end selfsabotage get everything you want paperback buddha said holding on to anger is like grasping a hot coal with the intent of throwing it at someone else you are the one who gets burned counseling a client with this wise saying she retorted forgiveness is not a concept in my religion well we are all holding on to anger of one sort or another against one parent or another an exlover exhusband exemployer etc and forgive to win finally explains fully and completely why its necessary and in our own best interests to let it go whatever your beliefs there are many wonderful books on forgiveness already on my bookshelf but i welcomed this one because it lays out a structured daily program its not just a philosophical treatise the steps suggested help train ourselves to let go of selfsabotaging behavior and learn to love ourselves by loving and forgiving others no matter what theyve done once our selfesteem is raised to the heights possible through selflove theres nothing you cant achieve forgiveness may seem like an easy task but its not and dr jacobson guides the reader in how to forgive his forgiveness diet is a unique set of recommendations to help us establish and maintain the NUM day commitment to acts of kindness and forgiveness that could literally change ones life he also includes forgiveness affirmations and visualizations that i have already used to great benefit looking at it from the vantage point of health anger throws us offbalance and creates tension that can lead to chronic pain and disease forgiveness opens the floodgates of our bodys own healing energy and keeps us grounded alert empowered and able to recognize opportunities for success the last chapter of the book is entitled getting everything you want if you dont already have it its time to get this book namaste becca chopra author of the chakra diaries URL</td><td>0.26</td><td>0.045</td><td>0.695</td><td>0.9979</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "spoiler alert girl meets lion lion meets burglar burglar meets nasty end girl cleans up evidence the end",
         0.101,
         0.165,
         0.734,
         -0.34
        ],
        [
         "a little gruesome the robber gets munch out of existence if it doesnt got over your head but my son loved this book the drawings are fun and the rhyming story is cute",
         0.314,
         0.049,
         0.637,
         0.9278
        ],
        [
         "an important word to the church you can be an obstacle or you can be a nurturer of gifts and callings of young people called to ministry my full review is found here URL",
         0.126,
         0.067,
         0.806,
         0.296
        ],
        [
         "jocelyn dreams of max almost every night but last night was different its christmas morning and last nights dreams weigh heavy on her mind as she waits for her visiting old college room mate to wake to talk to her first a ghost here crazy grandmothers ghost warning and wanting to help her then three visitors after that and not all were welcomed guests past present and future men collide in one night oh this novella is a very interesting and sexy vampire twist on a christmas carol oh the hints in this novella there is something special about jocelyn what im curious max is remembered and im curious how he manages to do this the current boyfriend that cute guy named chad from the dance in of course i tryyeah its him yum jocelyn has been trying to be stronger since max shes started selfdefense classes and fighting better along with becoming more physically fit than she ever has i have to say i love the description of the ghost yes its someone she knew shes the antithesis of the fairy godmother id always wished for all she needs now is a lit cigar between her fingers to totally bastardize that particular childhood fantasy the telling of this story starts with jocelyn waiting for kait then when she comes out we get the front row seat of the happenings as we are there with her then we are back to the morning and kait leaves and jocelyn gets ready for christmas at her mothers and waits for her boyfriend we seen clues that last night might not have been a dream but then things change and answers arent connecting with what happened so maybe it all was after being out with the girls drinking and all im left curious as to what was real and what was a dream i think its all real but there is more than real and not here theres secrets i want to know what they are there is something special about jocelyn but im not sure what exactly it is ill definitely be reading the first novel kiss of death very soon to figure it all out this is definitely a romance with intimate moments",
         0.174,
         0.104,
         0.722,
         0.9877
        ],
        [
         "NUM out of NUM stars why and how to forgive and reap the benefits october NUM NUM by becca chopra author of the chakra diaries big island of hawaii see all my reviews vine voice this review is from forgive to win end selfsabotage get everything you want paperback buddha said holding on to anger is like grasping a hot coal with the intent of throwing it at someone else you are the one who gets burned counseling a client with this wise saying she retorted forgiveness is not a concept in my religion well we are all holding on to anger of one sort or another against one parent or another an exlover exhusband exemployer etc and forgive to win finally explains fully and completely why its necessary and in our own best interests to let it go whatever your beliefs there are many wonderful books on forgiveness already on my bookshelf but i welcomed this one because it lays out a structured daily program its not just a philosophical treatise the steps suggested help train ourselves to let go of selfsabotaging behavior and learn to love ourselves by loving and forgiving others no matter what theyve done once our selfesteem is raised to the heights possible through selflove theres nothing you cant achieve forgiveness may seem like an easy task but its not and dr jacobson guides the reader in how to forgive his forgiveness diet is a unique set of recommendations to help us establish and maintain the NUM day commitment to acts of kindness and forgiveness that could literally change ones life he also includes forgiveness affirmations and visualizations that i have already used to great benefit looking at it from the vantage point of health anger throws us offbalance and creates tension that can lead to chronic pain and disease forgiveness opens the floodgates of our bodys own healing energy and keeps us grounded alert empowered and able to recognize opportunities for success the last chapter of the book is entitled getting everything you want if you dont already have it its time to get this book namaste becca chopra author of the chakra diaries URL",
         0.26,
         0.045,
         0.695,
         0.9979
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "review_text",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "sentiment_pos",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "sentiment_neg",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "sentiment_neu",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "sentiment_compound",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Sentiment Features ---\n",
    "\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "# Download VADER lexicon \n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Create the analyzer on the driver\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Define helper UDFs for each sentiment score\n",
    "@udf(DoubleType())\n",
    "def get_sent_pos(text):\n",
    "    return float(sia.polarity_scores(text)['pos']) if text else None\n",
    "\n",
    "@udf(DoubleType())\n",
    "def get_sent_neg(text):\n",
    "    return float(sia.polarity_scores(text)['neg']) if text else None\n",
    "\n",
    "@udf(DoubleType())\n",
    "def get_sent_neu(text):\n",
    "    return float(sia.polarity_scores(text)['neu']) if text else None\n",
    "\n",
    "@udf(DoubleType())\n",
    "def get_sent_compound(text):\n",
    "    return float(sia.polarity_scores(text)['compound']) if text else None\n",
    "\n",
    "# Apply UDFs to add sentiment columns\n",
    "train_df = (\n",
    "    train_df\n",
    "    .withColumn(\"sentiment_pos\", get_sent_pos(col(\"review_text\")))\n",
    "    .withColumn(\"sentiment_neg\", get_sent_neg(col(\"review_text\")))\n",
    "    .withColumn(\"sentiment_neu\", get_sent_neu(col(\"review_text\")))\n",
    "    .withColumn(\"sentiment_compound\", get_sent_compound(col(\"review_text\")))\n",
    ")\n",
    "\n",
    "# Preview a few rows\n",
    "display(train_df.select(\"review_text\", \"sentiment_pos\", \"sentiment_neg\", \"sentiment_neu\", \"sentiment_compound\").limit(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28383c79-54b4-4b86-820e-f7cb7cd0811e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ab3c477-ae5e-42db-9747-671ed1076aff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /databricks/python3/lib/python3.12/site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /databricks/python3/lib/python3.12/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /databricks/python3/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /databricks/python3/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.12/site-packages (from scikit-learn) (2.2.0)\n",
      "\u001b[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02c0f44b-ed50-4d6e-bad1-4b1fdd9097ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size: 671251\n",
      "TF-IDF matrix shape: (671251, 5000)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>19th</th>\n",
       "      <th>1st</th>\n",
       "      <th>20th</th>\n",
       "      <th>2nd</th>\n",
       "      <th>3rd</th>\n",
       "      <th>aaron</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abby</th>\n",
       "      <th>aber</th>\n",
       "      <th>abilities</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abrupt</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>absolutely love</th>\n",
       "      <th>absolutely loved</th>\n",
       "      <th>abuse</th>\n",
       "      <th>abused</th>\n",
       "      <th>abusive</th>\n",
       "      <th>academic</th>\n",
       "      <th>academy</th>\n",
       "      <th>accept</th>\n",
       "      <th>acceptance</th>\n",
       "      <th>accepted</th>\n",
       "      <th>accepting</th>\n",
       "      <th>access</th>\n",
       "      <th>accessible</th>\n",
       "      <th>accident</th>\n",
       "      <th>accidentally</th>\n",
       "      <th>accomplished</th>\n",
       "      <th>according</th>\n",
       "      <th>account</th>\n",
       "      <th>accounts</th>\n",
       "      <th>accurate</th>\n",
       "      <th>accused</th>\n",
       "      <th>achieve</th>\n",
       "      <th>act</th>\n",
       "      <th>acted</th>\n",
       "      <th>acting</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>year old</th>\n",
       "      <th>yearold</th>\n",
       "      <th>years</th>\n",
       "      <th>years ago</th>\n",
       "      <th>years later</th>\n",
       "      <th>years old</th>\n",
       "      <th>yes</th>\n",
       "      <th>yg</th>\n",
       "      <th>ykwn</th>\n",
       "      <th>yn</th>\n",
       "      <th>yo</th>\n",
       "      <th>york</th>\n",
       "      <th>york city</th>\n",
       "      <th>youd</th>\n",
       "      <th>youll</th>\n",
       "      <th>young</th>\n",
       "      <th>young adult</th>\n",
       "      <th>young girl</th>\n",
       "      <th>young man</th>\n",
       "      <th>young readers</th>\n",
       "      <th>young woman</th>\n",
       "      <th>younger</th>\n",
       "      <th>youre</th>\n",
       "      <th>youre going</th>\n",
       "      <th>youre looking</th>\n",
       "      <th>youth</th>\n",
       "      <th>youve</th>\n",
       "      <th>youve read</th>\n",
       "      <th>za</th>\n",
       "      <th>zach</th>\n",
       "      <th>ze</th>\n",
       "      <th>zero</th>\n",
       "      <th>zijn</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombies</th>\n",
       "      <th>zone</th>\n",
       "      <th>zu</th>\n",
       "      <th>zum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.118481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   19th  1st  20th       2nd  3rd  aaron  ...  zoe  zombie  zombies  zone   zu  zum\n",
       "0   0.0  0.0   0.0  0.000000  0.0    0.0  ...  0.0     0.0      0.0   0.0  0.0  0.0\n",
       "1   0.0  0.0   0.0  0.118481  0.0    0.0  ...  0.0     0.0      0.0   0.0  0.0  0.0\n",
       "2   0.0  0.0   0.0  0.000000  0.0    0.0  ...  0.0     0.0      0.0   0.0  0.0  0.0\n",
       "3   0.0  0.0   0.0  0.000000  0.0    0.0  ...  0.0     0.0      0.0   0.0  0.0  0.0\n",
       "4   0.0  0.0   0.0  0.000000  0.0    0.0  ...  0.0     0.0      0.0   0.0  0.0  0.0\n",
       "\n",
       "[5 rows x 5000 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- TF-IDF / CountVectorizer Feature Extraction using scikit-learn ---\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Convert Spark DataFrame to Pandas \n",
    "train_pdf = train_df.select(\"review_text\").sample(fraction=0.1, seed=60105179).toPandas()\n",
    "\n",
    "print(\"Sample size:\", len(train_pdf))\n",
    "\n",
    "# Step 2: Initialize CountVectorizer\n",
    "count_vect = CountVectorizer(\n",
    "    max_features=5000,        # top N terms\n",
    "    stop_words='english',     # remove filler words\n",
    "    ngram_range=(1, 2)        # unigrams and bigrams\n",
    ")\n",
    "\n",
    "# Step 3: Fit and transform\n",
    "X_counts = count_vect.fit_transform(train_pdf[\"review_text\"])\n",
    "\n",
    "# Step 4: Transform counts into TF-IDF\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_tfidf = tfidf_transformer.fit_transform(X_counts)\n",
    "\n",
    "# Step 5: Convert to DataFrame\n",
    "tfidf_df = pd.DataFrame(\n",
    "    X_tfidf.toarray(),\n",
    "    columns=count_vect.get_feature_names_out()\n",
    ")\n",
    "\n",
    "print(\"TF-IDF matrix shape:\", tfidf_df.shape)\n",
    "tfidf_df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dedd8308-8906-4e9d-8790-710f5d55c06a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### b. Sentiment Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9ec6c37-4e41-474c-ae4f-012d3ce5fd7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Step 1 – Install required libraries\n",
    "%pip install -q sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ad16db5-44fc-453d-924e-a54b17aff1bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size for embeddings: 671251\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff6889c5c39f4e70a7d8669c95e5a4cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0097715884074b7994bdfe9d18192466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1708141c25e4969b46b196ac60329d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9905b93f33134504bb1a3a7af6b1c3d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "617ec1c6e5714d18b8be161a5c2b5e5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cc9745ade55488aa21866ee4adbae28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d615d92f5a44803a0554fc2f37b7a4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3199815980147a7989ec83e1fb7522c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55d3ed09898d430b9820481d49b5d43b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49ab97ab4ac04c8687fbf00b4f7caf0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c24846a48b4430da053edac4a98b597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfb7312348f540b6a92cbfc0c52674e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/20977 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>bert_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entertaining story but a bit of a mess when it...</td>\n",
       "      <td>[-0.01206240151077509, 0.007737279869616032, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>emperors edge is the second book from lindsay ...</td>\n",
       "      <td>[-0.04844294488430023, -0.10820366442203522, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text                                     bert_embedding\n",
       "0  entertaining story but a bit of a mess when it...  [-0.01206240151077509, 0.007737279869616032, -...\n",
       "1  emperors edge is the second book from lindsay ...  [-0.04844294488430023, -0.10820366442203522, 0..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Transformer-based Embeddings (Sentence-BERT) ---\n",
    "\n",
    "\n",
    "# Step 2 – Import the model\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Step 3 – Convert a safe sample of the training data to Pandas\n",
    "train_sample = train_df.sample(fraction=0.1, seed=60105179).toPandas()\n",
    "\n",
    "print(\"Sample size for embeddings:\", len(train_sample))\n",
    "\n",
    "# Step 4 – Load a pre-trained Sentence-BERT model\n",
    "# (DistilBERT version is small and fast)\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Step 5 – Generate embeddings for each review\n",
    "embeddings = model.encode(train_sample[\"review_text\"].tolist(), show_progress_bar=True)\n",
    "\n",
    "# Step 6 – Store embeddings as a list of vectors\n",
    "train_sample[\"bert_embedding\"] = embeddings.tolist()\n",
    "\n",
    "# Step 7 – Preview results\n",
    "train_sample[[\"review_text\", \"bert_embedding\"]].head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1ac8007-e8cd-44e6-970b-4c117fb04acf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Additional features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "194b63b2-b4c0-490e-a218-adba30a0975e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "To include additional features, i engineered simple metrics that capture writing style, tone, and behavior:\n",
    "\n",
    "Average Word Length – measures writing complexity.\n",
    "\n",
    "Unique Word Ratio – indicates vocabulary diversity.\n",
    "\n",
    "Exclamation Count – reflects emotional intensity.\n",
    "\n",
    "Contains URL – flags reviews mentioning links.\n",
    "\n",
    "Sentiment Label – derived from compound sentiment score to classify overall polarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c559bcd7-8800-47fb-a9e9-efda8a1aaca9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>review_text</th><th>avg_word_length</th><th>unique_word_ratio</th><th>exclamation_count</th><th>contains_url</th><th>sentiment_label</th></tr></thead><tbody><tr><td>spoiler alert girl meets lion lion meets burglar burglar meets nasty end girl cleans up evidence the end</td><td>5.473684210526316</td><td>0.9473684210526315</td><td>0</td><td>0</td><td>negative</td></tr><tr><td>a little gruesome the robber gets munch out of existence if it doesnt got over your head but my son loved this book the drawings are fun and the rhyming story is cute</td><td>4.882352941176471</td><td>0.9705882352941176</td><td>0</td><td>0</td><td>positive</td></tr><tr><td>an important word to the church you can be an obstacle or you can be a nurturer of gifts and callings of young people called to ministry my full review is found here URL</td><td>4.828571428571428</td><td>0.9714285714285714</td><td>0</td><td>0</td><td>positive</td></tr><tr><td>jocelyn dreams of max almost every night but last night was different its christmas morning and last nights dreams weigh heavy on her mind as she waits for her visiting old college room mate to wake to talk to her first a ghost here crazy grandmothers ghost warning and wanting to help her then three visitors after that and not all were welcomed guests past present and future men collide in one night oh this novella is a very interesting and sexy vampire twist on a christmas carol oh the hints in this novella there is something special about jocelyn what im curious max is remembered and im curious how he manages to do this the current boyfriend that cute guy named chad from the dance in of course i tryyeah its him yum jocelyn has been trying to be stronger since max shes started selfdefense classes and fighting better along with becoming more physically fit than she ever has i have to say i love the description of the ghost yes its someone she knew shes the antithesis of the fairy godmother id always wished for all she needs now is a lit cigar between her fingers to totally bastardize that particular childhood fantasy the telling of this story starts with jocelyn waiting for kait then when she comes out we get the front row seat of the happenings as we are there with her then we are back to the morning and kait leaves and jocelyn gets ready for christmas at her mothers and waits for her boyfriend we seen clues that last night might not have been a dream but then things change and answers arent connecting with what happened so maybe it all was after being out with the girls drinking and all im left curious as to what was real and what was a dream i think its all real but there is more than real and not here theres secrets i want to know what they are there is something special about jocelyn but im not sure what exactly it is ill definitely be reading the first novel kiss of death very soon to figure it all out this is definitely a romance with intimate moments</td><td>5.340482573726542</td><td>0.9973190348525469</td><td>0</td><td>0</td><td>positive</td></tr><tr><td>NUM out of NUM stars why and how to forgive and reap the benefits october NUM NUM by becca chopra author of the chakra diaries big island of hawaii see all my reviews vine voice this review is from forgive to win end selfsabotage get everything you want paperback buddha said holding on to anger is like grasping a hot coal with the intent of throwing it at someone else you are the one who gets burned counseling a client with this wise saying she retorted forgiveness is not a concept in my religion well we are all holding on to anger of one sort or another against one parent or another an exlover exhusband exemployer etc and forgive to win finally explains fully and completely why its necessary and in our own best interests to let it go whatever your beliefs there are many wonderful books on forgiveness already on my bookshelf but i welcomed this one because it lays out a structured daily program its not just a philosophical treatise the steps suggested help train ourselves to let go of selfsabotaging behavior and learn to love ourselves by loving and forgiving others no matter what theyve done once our selfesteem is raised to the heights possible through selflove theres nothing you cant achieve forgiveness may seem like an easy task but its not and dr jacobson guides the reader in how to forgive his forgiveness diet is a unique set of recommendations to help us establish and maintain the NUM day commitment to acts of kindness and forgiveness that could literally change ones life he also includes forgiveness affirmations and visualizations that i have already used to great benefit looking at it from the vantage point of health anger throws us offbalance and creates tension that can lead to chronic pain and disease forgiveness opens the floodgates of our bodys own healing energy and keeps us grounded alert empowered and able to recognize opportunities for success the last chapter of the book is entitled getting everything you want if you dont already have it its time to get this book namaste becca chopra author of the chakra diaries URL</td><td>5.7154696132596685</td><td>0.9972375690607734</td><td>0</td><td>0</td><td>positive</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "spoiler alert girl meets lion lion meets burglar burglar meets nasty end girl cleans up evidence the end",
         5.473684210526316,
         0.9473684210526315,
         0,
         0,
         "negative"
        ],
        [
         "a little gruesome the robber gets munch out of existence if it doesnt got over your head but my son loved this book the drawings are fun and the rhyming story is cute",
         4.882352941176471,
         0.9705882352941176,
         0,
         0,
         "positive"
        ],
        [
         "an important word to the church you can be an obstacle or you can be a nurturer of gifts and callings of young people called to ministry my full review is found here URL",
         4.828571428571428,
         0.9714285714285714,
         0,
         0,
         "positive"
        ],
        [
         "jocelyn dreams of max almost every night but last night was different its christmas morning and last nights dreams weigh heavy on her mind as she waits for her visiting old college room mate to wake to talk to her first a ghost here crazy grandmothers ghost warning and wanting to help her then three visitors after that and not all were welcomed guests past present and future men collide in one night oh this novella is a very interesting and sexy vampire twist on a christmas carol oh the hints in this novella there is something special about jocelyn what im curious max is remembered and im curious how he manages to do this the current boyfriend that cute guy named chad from the dance in of course i tryyeah its him yum jocelyn has been trying to be stronger since max shes started selfdefense classes and fighting better along with becoming more physically fit than she ever has i have to say i love the description of the ghost yes its someone she knew shes the antithesis of the fairy godmother id always wished for all she needs now is a lit cigar between her fingers to totally bastardize that particular childhood fantasy the telling of this story starts with jocelyn waiting for kait then when she comes out we get the front row seat of the happenings as we are there with her then we are back to the morning and kait leaves and jocelyn gets ready for christmas at her mothers and waits for her boyfriend we seen clues that last night might not have been a dream but then things change and answers arent connecting with what happened so maybe it all was after being out with the girls drinking and all im left curious as to what was real and what was a dream i think its all real but there is more than real and not here theres secrets i want to know what they are there is something special about jocelyn but im not sure what exactly it is ill definitely be reading the first novel kiss of death very soon to figure it all out this is definitely a romance with intimate moments",
         5.340482573726542,
         0.9973190348525469,
         0,
         0,
         "positive"
        ],
        [
         "NUM out of NUM stars why and how to forgive and reap the benefits october NUM NUM by becca chopra author of the chakra diaries big island of hawaii see all my reviews vine voice this review is from forgive to win end selfsabotage get everything you want paperback buddha said holding on to anger is like grasping a hot coal with the intent of throwing it at someone else you are the one who gets burned counseling a client with this wise saying she retorted forgiveness is not a concept in my religion well we are all holding on to anger of one sort or another against one parent or another an exlover exhusband exemployer etc and forgive to win finally explains fully and completely why its necessary and in our own best interests to let it go whatever your beliefs there are many wonderful books on forgiveness already on my bookshelf but i welcomed this one because it lays out a structured daily program its not just a philosophical treatise the steps suggested help train ourselves to let go of selfsabotaging behavior and learn to love ourselves by loving and forgiving others no matter what theyve done once our selfesteem is raised to the heights possible through selflove theres nothing you cant achieve forgiveness may seem like an easy task but its not and dr jacobson guides the reader in how to forgive his forgiveness diet is a unique set of recommendations to help us establish and maintain the NUM day commitment to acts of kindness and forgiveness that could literally change ones life he also includes forgiveness affirmations and visualizations that i have already used to great benefit looking at it from the vantage point of health anger throws us offbalance and creates tension that can lead to chronic pain and disease forgiveness opens the floodgates of our bodys own healing energy and keeps us grounded alert empowered and able to recognize opportunities for success the last chapter of the book is entitled getting everything you want if you dont already have it its time to get this book namaste becca chopra author of the chakra diaries URL",
         5.7154696132596685,
         0.9972375690607734,
         0,
         0,
         "positive"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "review_text",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "avg_word_length",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "unique_word_ratio",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "exclamation_count",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "contains_url",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "sentiment_label",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, length, split, lower, regexp_replace, size, udf\n",
    "from pyspark.sql.types import StringType, DoubleType\n",
    "\n",
    "# --- 1 Average Word Length ---\n",
    "train_df = train_df.withColumn(\n",
    "    \"avg_word_length\",\n",
    "    (length(col(\"review_text\")) / (size(split(col(\"review_text\"), \" \")) + 1))\n",
    ")\n",
    "\n",
    "# --- 2️ Unique Word Ratio ---\n",
    "train_df = train_df.withColumn(\n",
    "    \"unique_word_ratio\",\n",
    "    (size(split(lower(regexp_replace(col(\"review_text\"), \"[^a-zA-Z\\\\s]\", \"\")), \" \")) /\n",
    "     (size(split(col(\"review_text\"), \" \")) + 1))\n",
    ")\n",
    "\n",
    "# --- 3️ Exclamation Count ---\n",
    "train_df = train_df.withColumn(\n",
    "    \"exclamation_count\",\n",
    "    length(col(\"review_text\")) - length(regexp_replace(col(\"review_text\"), \"!\", \"\"))\n",
    ")\n",
    "\n",
    "# --- 4️ Contains URL Flag ---\n",
    "train_df = train_df.withColumn(\n",
    "    \"contains_url\",\n",
    "    (col(\"review_text\").rlike(\"http|www\")).cast(\"int\")\n",
    ")\n",
    "\n",
    "# --- 5️ Sentiment Label (from compound score) ---\n",
    "def label_sentiment(c):\n",
    "    if c is None:\n",
    "        return None\n",
    "    elif c >= 0.05:\n",
    "        return \"positive\"\n",
    "    elif c <= -0.05:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    "\n",
    "label_udf = udf(label_sentiment, StringType())\n",
    "train_df = train_df.withColumn(\"sentiment_label\", label_udf(col(\"sentiment_compound\")))\n",
    "\n",
    "# --- Preview results ---\n",
    "display(train_df.select(\n",
    "    \"review_text\", \n",
    "    \"avg_word_length\", \n",
    "    \"unique_word_ratio\", \n",
    "    \"exclamation_count\", \n",
    "    \"contains_url\",\n",
    "    \"sentiment_label\"\n",
    ").limit(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7dd33e69-c30d-4a4b-a7f9-f0714ec9d73c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Combined Feature Set and Output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f64fdd8-56ea-4a02-ac9e-acd17caf1ef9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
       "\u001b[0;31mThe Python process exited with exit code 137 (SIGKILL: Killed). This may have been caused by an OOM error. Check your command's memory usage.\u001b[0m\n",
       "\u001b[0;31m\u001b[0m\n",
       "\u001b[0;31m\u001b[0m\n",
       "\u001b[0;31m\u001b[0m\n",
       "\u001b[0;31mThe last 10 KB of the process's stderr and stdout can be found below. See driver logs for full logs.\u001b[0m\n",
       "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
       "\u001b[0;31mLast messages on stderr:\u001b[0m\n",
       "\u001b[0;31mWed Nov 12 21:32:15 2025 Connection to spark from PID  3015\u001b[0m\n",
       "\u001b[0;31mWed Nov 12 21:32:16 2025 Initialized gateway on port 38051\u001b[0m\n",
       "\u001b[0;31m/databricks/python/lib/python3.12/site-packages/databricks/sdk/service/jobs.py:60: SyntaxWarning: invalid escape sequence '\\.'\u001b[0m\n",
       "\u001b[0;31m  \"\"\"The sequence number of this run attempt for a triggered job run. The initial attempt of a run\u001b[0m\n",
       "\u001b[0;31m/databricks/python/lib/python3.12/site-packages/databricks/sdk/service/jobs.py:2570: SyntaxWarning: invalid escape sequence '\\.'\u001b[0m\n",
       "\u001b[0;31m  \"\"\"The sequence number of this run attempt for a triggered job run. The initial attempt of a run\u001b[0m\n",
       "\u001b[0;31m/databricks/python/lib/python3.12/site-packages/databricks/sdk/service/jobs.py:3431: SyntaxWarning: invalid escape sequence '\\.'\u001b[0m\n",
       "\u001b[0;31m  \"\"\"The sequence number of this run attempt for a triggered job run. The initial attempt of a run\u001b[0m\n",
       "\u001b[0;31mWed Nov 12 21:32:18 2025 Connected to spark.\u001b[0m\n",
       "\u001b[0;31m[nltk_data] Downloading package vader_lexicon to\u001b[0m\n",
       "\u001b[0;31m[nltk_data]     /home/spark-6a3e73ef-c784-4316-b3b1-4b/nltk_data...\u001b[0m\n",
       "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
       "\u001b[0;31mLast messages on stdout:\u001b[0m\n",
       "\u001b[0;31mNOTE: When using the `ipython kernel` entry point, Ctrl-C will not work.\u001b[0m\n",
       "\u001b[0;31m\u001b[0m\n",
       "\u001b[0;31mTo exit, you will have to explicitly quit this process, by either sending\u001b[0m\n",
       "\u001b[0;31m\"quit\" from a client, or using Ctrl-\\ in UNIX-like environments.\u001b[0m\n",
       "\u001b[0;31m\u001b[0m\n",
       "\u001b[0;31mTo read more about this, see https://github.com/ipython/ipython/issues/2049\u001b[0m\n",
       "\u001b[0;31m\u001b[0m\n",
       "\u001b[0;31m\u001b[0m\n",
       "\u001b[0;31mTo connect another client to this kernel, use:\u001b[0m\n",
       "\u001b[0;31m    --existing /databricks/kernel-connections/d98604cb5a81c1bab30551860201b38cc01c19e5196d57c3515a16b64617404e.json\u001b[0m\n",
       "\u001b[0;31mroot\u001b[0m\n",
       "\u001b[0;31m-- book_id: string (nullable = true)\u001b[0m\n",
       "\u001b[0;31m-- review_id: string (nullable = true)\u001b[0m\n",
       "\u001b[0;31m-- title: string (nullable = true)\u001b[0m\n",
       "\u001b[0;31m-- author_id: string (nullable = true)\u001b[0m\n",
       "\u001b[0;31m-- author_name: string (nullable = true)\u001b[0m\n",
       "\u001b[0;31m-- user_id: string (nullable = true)\u001b[0m\n",
       "\u001b[0;31m-- rating: float (nullable = true)\u001b[0m\n",
       "\u001b[0;31m-- review_text: string (nullable = true)\u001b[0m\n",
       "\u001b[0;31m-- language_code: string (nullable = true)\u001b[0m\n",
       "\u001b[0;31m-- n_votes: integer (nullable = true)\u001b[0m\n",
       "\u001b[0;31m-- date_added: date (nullable = true)\u001b[0m\n",
       "\u001b[0;31m-- review_length: integer (nullable = true)\u001b[0m\n",
       "\u001b[0;31m-- review_length_in_words: integer (nullable = true)\u001b[0m\n",
       "\u001b[0;31m-- average_rating: double (nullable = true)\u001b[0m\n",
       "\u001b[0;31m-- number_of_reviews: long (nullable = true)\u001b[0m\n",
       "\u001b[0;31m\u001b[0m\n",
       "\u001b[0;31mTrain rows: 6759016\u001b[0m\n",
       "\u001b[0;31mValidation rows: 1446141\u001b[0m\n",
       "\u001b[0;31mTest rows: 1447906\u001b[0m\n",
       "\u001b[0;31mCollecting emoji\u001b[0m\n",
       "\u001b[0;31m  Downloading emoji-2.15.0-py3-none-any.whl.metadata (5.7 kB)\u001b[0m\n",
       "\u001b[0;31mDownloading emoji-2.15.0-py3-none-any.whl (608 kB)\u001b[0m\n",
       "\u001b[0;31m\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/608.4 kB ? eta -:--:--\u001b[0m\n",
       "\u001b[0;31m\u001b[2K   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 608.4/608.4 kB 19.9 MB/s eta 0:00:00\u001b[0m\n",
       "\u001b[0;31m\u001b[?25hInstalling collected packages: emoji\u001b[0m\n",
       "\u001b[0;31mSuccessfully installed emoji-2.15.0\u001b[0m\n",
       "\u001b[0;31mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001b[0m\n",
       "\u001b[0;31mCollecting nltk\u001b[0m\n",
       "\u001b[0;31m  Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\u001b[0m\n",
       "\u001b[0;31mRequirement already satisfied: click in /databricks/python3/lib/python3.12/site-packages (from nltk) (8.1.7)\u001b[0m\n",
       "\u001b[0;31mRequirement already satisfied: joblib in /databricks/python3/lib/python3.12/site-packages (from nltk) (1.4.2)\u001b[0m\n",
       "\u001b[0;31mCollecting regex>=2021.8.3 (from nltk)\u001b[0m\n",
       "\u001b[0;31m  Downloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\u001b[0m\n",
       "\u001b[0;31m\u001b[?25l     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/40.5 kB ? eta -:--:--\u001b[0m\n",
       "\u001b[0;31m\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.5/40.5 kB 2.2 MB/s eta 0:00:00\u001b[0m\n",
       "\u001b[0;31m\u001b[?25hCollecting tqdm (from nltk)\u001b[0m\n",
       "\u001b[0;31m  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\u001b[0m\n",
       "\u001b[0;31m\u001b[?25l     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/57.7 kB ? eta -:--:--\u001b[0m\n",
       "\u001b[0;31m\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.7/57.7 kB 3.6 MB/s eta 0:00:00\u001b[0m\n",
       "\u001b[0;31m\u001b[?25hDownloading nltk-3.9.2-py3-none-any.whl (1.5 MB)\u001b[0m\n",
       "\u001b[0;31m\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/1.5 MB ? eta -:--:--\u001b[0m\n",
       "\u001b[0;31m\u001b[2K   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.5/1.5 MB 58.3 MB/s eta 0:00:00\u001b[0m\n",
       "\u001b[0;31m\u001b[?25hDownloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (803 kB)\u001b[0m\n",
       "\u001b[0;31m\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/803.5 kB ? eta -:--:--\u001b[0m\n",
       "\u001b[0;31m\u001b[2K   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 803.5/803.5 kB 43.7 MB/s eta 0:00:00\u001b[0m\n",
       "\u001b[0;31m\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\u001b[0m\n",
       "\u001b[0;31m\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/78.5 kB ? eta -:--:--\u001b[0m\n",
       "\u001b[0;31m\u001b[2K   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.5/78.5 kB 6.6 MB/s eta 0:00:00\u001b[0m\n",
       "\u001b[0;31m\u001b[?25hInstalling collected packages: tqdm, regex, nltk\u001b[0m\n",
       "\u001b[0;31mSuccessfully installed nltk-3.9.2 regex-2025.11.3 tqdm-4.67.1\u001b[0m\n",
       "\u001b[0;31mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001b[0m\n",
       "\u001b[0;31mRequirement already satisfied: scikit-learn in /databricks/python3/lib/python3.12/site-packages (1.4.2)\u001b[0m\n",
       "\u001b[0;31mRequirement already satisfied: numpy>=1.19.5 in /databricks/python3/lib/python3.12/site-packages (from scikit-learn) (1.26.4)\u001b[0m\n",
       "\u001b[0;31mRequirement already satisfied: scipy>=1.6.0 in /databricks/python3/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\u001b[0m\n",
       "\u001b[0;31mRequirement already satisfied: joblib>=1.2.0 in /databricks/python3/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\u001b[0m\n",
       "\u001b[0;31mRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.12/site-packages (from scikit-learn) (2.2.0)\u001b[0m\n",
       "\u001b[0;31mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001b[0m\n",
       "\u001b[0;31mSample size: 671251\u001b[0m\n",
       "\u001b[0;31mTF-IDF matrix shape: (671251, 5000)\u001b[0m\n",
       "\u001b[0;31mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001b[0m\n",
       "\u001b[0;31mSample size for embeddings: 671251\u001b[0m"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mThe Python process exited with exit code 137 (SIGKILL: Killed). This may have been caused by an OOM error. Check your command's memory usage.\u001b[0m\n\u001b[0;31m\u001b[0m\n\u001b[0;31m\u001b[0m\n\u001b[0;31m\u001b[0m\n\u001b[0;31mThe last 10 KB of the process's stderr and stdout can be found below. See driver logs for full logs.\u001b[0m\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mLast messages on stderr:\u001b[0m\n\u001b[0;31mWed Nov 12 21:32:15 2025 Connection to spark from PID  3015\u001b[0m\n\u001b[0;31mWed Nov 12 21:32:16 2025 Initialized gateway on port 38051\u001b[0m\n\u001b[0;31m/databricks/python/lib/python3.12/site-packages/databricks/sdk/service/jobs.py:60: SyntaxWarning: invalid escape sequence '\\.'\u001b[0m\n\u001b[0;31m  \"\"\"The sequence number of this run attempt for a triggered job run. The initial attempt of a run\u001b[0m\n\u001b[0;31m/databricks/python/lib/python3.12/site-packages/databricks/sdk/service/jobs.py:2570: SyntaxWarning: invalid escape sequence '\\.'\u001b[0m\n\u001b[0;31m  \"\"\"The sequence number of this run attempt for a triggered job run. The initial attempt of a run\u001b[0m\n\u001b[0;31m/databricks/python/lib/python3.12/site-packages/databricks/sdk/service/jobs.py:3431: SyntaxWarning: invalid escape sequence '\\.'\u001b[0m\n\u001b[0;31m  \"\"\"The sequence number of this run attempt for a triggered job run. The initial attempt of a run\u001b[0m\n\u001b[0;31mWed Nov 12 21:32:18 2025 Connected to spark.\u001b[0m\n\u001b[0;31m[nltk_data] Downloading package vader_lexicon to\u001b[0m\n\u001b[0;31m[nltk_data]     /home/spark-6a3e73ef-c784-4316-b3b1-4b/nltk_data...\u001b[0m\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mLast messages on stdout:\u001b[0m\n\u001b[0;31mNOTE: When using the `ipython kernel` entry point, Ctrl-C will not work.\u001b[0m\n\u001b[0;31m\u001b[0m\n\u001b[0;31mTo exit, you will have to explicitly quit this process, by either sending\u001b[0m\n\u001b[0;31m\"quit\" from a client, or using Ctrl-\\ in UNIX-like environments.\u001b[0m\n\u001b[0;31m\u001b[0m\n\u001b[0;31mTo read more about this, see https://github.com/ipython/ipython/issues/2049\u001b[0m\n\u001b[0;31m\u001b[0m\n\u001b[0;31m\u001b[0m\n\u001b[0;31mTo connect another client to this kernel, use:\u001b[0m\n\u001b[0;31m    --existing /databricks/kernel-connections/d98604cb5a81c1bab30551860201b38cc01c19e5196d57c3515a16b64617404e.json\u001b[0m\n\u001b[0;31mroot\u001b[0m\n\u001b[0;31m-- book_id: string (nullable = true)\u001b[0m\n\u001b[0;31m-- review_id: string (nullable = true)\u001b[0m\n\u001b[0;31m-- title: string (nullable = true)\u001b[0m\n\u001b[0;31m-- author_id: string (nullable = true)\u001b[0m\n\u001b[0;31m-- author_name: string (nullable = true)\u001b[0m\n\u001b[0;31m-- user_id: string (nullable = true)\u001b[0m\n\u001b[0;31m-- rating: float (nullable = true)\u001b[0m\n\u001b[0;31m-- review_text: string (nullable = true)\u001b[0m\n\u001b[0;31m-- language_code: string (nullable = true)\u001b[0m\n\u001b[0;31m-- n_votes: integer (nullable = true)\u001b[0m\n\u001b[0;31m-- date_added: date (nullable = true)\u001b[0m\n\u001b[0;31m-- review_length: integer (nullable = true)\u001b[0m\n\u001b[0;31m-- review_length_in_words: integer (nullable = true)\u001b[0m\n\u001b[0;31m-- average_rating: double (nullable = true)\u001b[0m\n\u001b[0;31m-- number_of_reviews: long (nullable = true)\u001b[0m\n\u001b[0;31m\u001b[0m\n\u001b[0;31mTrain rows: 6759016\u001b[0m\n\u001b[0;31mValidation rows: 1446141\u001b[0m\n\u001b[0;31mTest rows: 1447906\u001b[0m\n\u001b[0;31mCollecting emoji\u001b[0m\n\u001b[0;31m  Downloading emoji-2.15.0-py3-none-any.whl.metadata (5.7 kB)\u001b[0m\n\u001b[0;31mDownloading emoji-2.15.0-py3-none-any.whl (608 kB)\u001b[0m\n\u001b[0;31m\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/608.4 kB ? eta -:--:--\u001b[0m\n\u001b[0;31m\u001b[2K   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 608.4/608.4 kB 19.9 MB/s eta 0:00:00\u001b[0m\n\u001b[0;31m\u001b[?25hInstalling collected packages: emoji\u001b[0m\n\u001b[0;31mSuccessfully installed emoji-2.15.0\u001b[0m\n\u001b[0;31mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001b[0m\n\u001b[0;31mCollecting nltk\u001b[0m\n\u001b[0;31m  Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\u001b[0m\n\u001b[0;31mRequirement already satisfied: click in /databricks/python3/lib/python3.12/site-packages (from nltk) (8.1.7)\u001b[0m\n\u001b[0;31mRequirement already satisfied: joblib in /databricks/python3/lib/python3.12/site-packages (from nltk) (1.4.2)\u001b[0m\n\u001b[0;31mCollecting regex>=2021.8.3 (from nltk)\u001b[0m\n\u001b[0;31m  Downloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\u001b[0m\n\u001b[0;31m\u001b[?25l     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/40.5 kB ? eta -:--:--\u001b[0m\n\u001b[0;31m\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.5/40.5 kB 2.2 MB/s eta 0:00:00\u001b[0m\n\u001b[0;31m\u001b[?25hCollecting tqdm (from nltk)\u001b[0m\n\u001b[0;31m  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\u001b[0m\n\u001b[0;31m\u001b[?25l     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/57.7 kB ? eta -:--:--\u001b[0m\n\u001b[0;31m\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.7/57.7 kB 3.6 MB/s eta 0:00:00\u001b[0m\n\u001b[0;31m\u001b[?25hDownloading nltk-3.9.2-py3-none-any.whl (1.5 MB)\u001b[0m\n\u001b[0;31m\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/1.5 MB ? eta -:--:--\u001b[0m\n\u001b[0;31m\u001b[2K   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.5/1.5 MB 58.3 MB/s eta 0:00:00\u001b[0m\n\u001b[0;31m\u001b[?25hDownloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (803 kB)\u001b[0m\n\u001b[0;31m\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/803.5 kB ? eta -:--:--\u001b[0m\n\u001b[0;31m\u001b[2K   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 803.5/803.5 kB 43.7 MB/s eta 0:00:00\u001b[0m\n\u001b[0;31m\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\u001b[0m\n\u001b[0;31m\u001b[?25l   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/78.5 kB ? eta -:--:--\u001b[0m\n\u001b[0;31m\u001b[2K   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.5/78.5 kB 6.6 MB/s eta 0:00:00\u001b[0m\n\u001b[0;31m\u001b[?25hInstalling collected packages: tqdm, regex, nltk\u001b[0m\n\u001b[0;31mSuccessfully installed nltk-3.9.2 regex-2025.11.3 tqdm-4.67.1\u001b[0m\n\u001b[0;31mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001b[0m\n\u001b[0;31mRequirement already satisfied: scikit-learn in /databricks/python3/lib/python3.12/site-packages (1.4.2)\u001b[0m\n\u001b[0;31mRequirement already satisfied: numpy>=1.19.5 in /databricks/python3/lib/python3.12/site-packages (from scikit-learn) (1.26.4)\u001b[0m\n\u001b[0;31mRequirement already satisfied: scipy>=1.6.0 in /databricks/python3/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\u001b[0m\n\u001b[0;31mRequirement already satisfied: joblib>=1.2.0 in /databricks/python3/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\u001b[0m\n\u001b[0;31mRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.12/site-packages (from scikit-learn) (2.2.0)\u001b[0m\n\u001b[0;31mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001b[0m\n\u001b[0;31mSample size: 671251\u001b[0m\n\u001b[0;31mTF-IDF matrix shape: (671251, 5000)\u001b[0m\n\u001b[0;31mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001b[0m\n\u001b[0;31mSample size for embeddings: 671251\u001b[0m",
       "errorSummary": "<span class='ansi-red-fg'>Fatal error</span>: The Python kernel is unresponsive.",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =====================================================\n",
    "# IV. Combined Feature Set and Output (Optimized Version)\n",
    "# =====================================================\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Step 1: Select key metadata columns\n",
    "metadata_df = train_df.select(\"review_id\", \"book_id\", \"rating\")\n",
    "\n",
    "# Step 2: Select engineered numeric features\n",
    "numeric_features_df = train_df.select(\n",
    "    \"review_id\",\n",
    "    \"review_length_words\",\n",
    "    \"review_length_chars\",\n",
    "    \"sentiment_pos\",\n",
    "    \"sentiment_neg\",\n",
    "    \"sentiment_neu\",\n",
    "    \"sentiment_compound\",\n",
    "    \"avg_word_length\",\n",
    "    \"unique_word_ratio\",\n",
    "    \"exclamation_count\",\n",
    "    \"contains_url\"\n",
    ")\n",
    "\n",
    "# Step 3: Convert TF-IDF (Pandas → Spark)\n",
    "# Make sure tfidf_df includes a review_id column\n",
    "tfidf_spark_df = spark.createDataFrame(tfidf_df)\n",
    "\n",
    "# Step 4: Convert BERT embeddings (Pandas → Spark)\n",
    "bert_spark_df = spark.createDataFrame(train_sample[[\"review_id\", \"bert_embedding\"]])\n",
    "\n",
    "# Step 5: Combine all features on review_id (inner joins)\n",
    "combined_df = (\n",
    "    metadata_df\n",
    "    .join(numeric_features_df, \"review_id\", \"inner\")\n",
    "    .join(tfidf_spark_df, \"review_id\", \"inner\")\n",
    "    .join(bert_spark_df, \"review_id\", \"inner\")\n",
    ")\n",
    "\n",
    "# Step 6: Save to Gold layer safely\n",
    "output_base = \"abfss://lakehouse@goodreadsreviews60105179.dfs.core.windows.net/gold/features_v2\"\n",
    "\n",
    "combined_df.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .save(f\"{output_base}/train_final\")\n",
    "\n",
    "print(\"✅ Combined feature dataset saved successfully to features_v2/train_final\")\n",
    "\n",
    "# Step 7: Lightweight sanity check (NO full count)\n",
    "print(f\"Number of columns: {len(combined_df.columns)}\")\n",
    "print(\"Sample records:\")\n",
    "display(combined_df.limit(5))\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "goodreads_text_features",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
